# VibeRS Project Structure

## ğŸ“ Directory Layout

```
VibeRS/
â”œâ”€â”€ cmd/                    # Application entry points
â”‚   â”œâ”€â”€ api/               # REST API server
â”‚   â”‚   â””â”€â”€ main.go        # API server main entry
â”‚   â”œâ”€â”€ batch/             # Batch processing jobs (placeholder)
â”‚   â””â”€â”€ cli/               # Command line tools (placeholder)
â”‚
â”œâ”€â”€ internal/              # Private application packages
â”‚   â”œâ”€â”€ store/             # Data access layer
â”‚   â”‚   â””â”€â”€ store.go       # SQLite operations & Item model
â”‚   â”œâ”€â”€ recall/            # Parallel recall strategies
â”‚   â”‚   â””â”€â”€ service.go     # Multi-strategy recall service
â”‚   â”œâ”€â”€ dedup/             # Deduplication logic
â”‚   â”‚   â””â”€â”€ service.go     # Min-heap based deduplication
â”‚   â”œâ”€â”€ rank/              # Three-stage ranking
â”‚   â”‚   â”œâ”€â”€ coarse/        # Hard rules & basic scoring
â”‚   â”‚   â”‚   â””â”€â”€ ranker.go  # Business rule engine
â”‚   â”‚   â”œâ”€â”€ ltr/           # Learning-to-Rank
â”‚   â”‚   â”‚   â””â”€â”€ ranker.go  # ML-based ranking (ONNX placeholder)
â”‚   â”‚   â””â”€â”€ final/         # Final business optimization
â”‚   â”‚       â””â”€â”€ ranker.go  # Diversity & GMV optimization
â”‚   â””â”€â”€ util/              # Shared utilities (placeholder)
â”‚
â”œâ”€â”€ data/                  # Database & sample data
â”‚   â”œâ”€â”€ ddl.sql           # Database schema definition
â”‚   â”œâ”€â”€ sample.csv        # 20 luxury handbag sample items
â”‚   â””â”€â”€ vibers.db         # SQLite database (created by init script)
â”‚
â”œâ”€â”€ model-training/        # Python ML pipeline
â”‚   â””â”€â”€ requirements.txt  # Python dependencies for model training
â”‚
â”œâ”€â”€ scripts/              # Automation scripts
â”‚   â”œâ”€â”€ db_init.sh        # Database initialization script
â”‚   â””â”€â”€ lint.sh           # Code quality checks
â”‚
â”œâ”€â”€ go.mod                # Go module definition
â”œâ”€â”€ Makefile              # Optional build automation
â””â”€â”€ README.md             # Main project documentation
```

## ğŸ”§ Key Components

### API Layer (`cmd/api/`)
- **main.go**: Gin-based REST API server
- Handles `/search` endpoint with JSON request/response
- Orchestrates the full search pipeline

### Data Layer (`internal/store/`)
- **store.go**: SQLite database operations
- Item model with all product attributes
- Full-text search, filtering, and vector similarity (placeholder)
- Custom SQLite UDF for cosine similarity

### Recall Layer (`internal/recall/`)
- **service.go**: Parallel recall execution
- 5 concurrent strategies: text, attribute, hot, explore, ANN
- Goroutine-based parallel processing

### Deduplication (`internal/dedup/`)
- **service.go**: Min-heap based deduplication
- Removes duplicate items by ID
- Maintains top-N items by relevance score

### Ranking Pipeline (`internal/rank/`)
- **coarse/ranker.go**: Hard business rules & basic scoring
- **ltr/ranker.go**: Machine learning based ranking (placeholder)
- **final/ranker.go**: Business optimization with diversity constraints

### Database (`data/`)
- **ddl.sql**: Complete SQLite schema with FTS5 and indexes
- **sample.csv**: 20 sample luxury handbag items
- Supports full-text search, filtering, and vector operations

### Scripts (`scripts/`)
- **db_init.sh**: Automated database setup and data import
- **lint.sh**: Code quality checks (go vet, fmt, mod tidy)

## ğŸš€ Quick Start

1. **Initialize Database**:
   ```bash
   ./scripts/db_init.sh
   ```

2. **Run API Server**:
   ```bash
   go run ./cmd/api
   ```

3. **Test Search**:
   ```bash
   curl -X POST localhost:8080/search -d '{"q":"lv bag","page":1}' | jq
   ```

## ğŸ“Š Current Status

- âœ… **Complete project structure** with all packages
- âœ… **Working API server** with search endpoint
- âœ… **Database schema** with sample data
- âœ… **Parallel recall** framework
- âœ… **Three-stage ranking** pipeline
- ğŸš§ **Vector similarity** (placeholder implementation)
- ğŸš§ **ONNX model integration** (placeholder)
- ğŸ“‹ **Unit tests** (to be added)

## ğŸ¯ Next Steps

1. Run database initialization
2. Test API functionality
3. Implement vector similarity UDF
4. Add ONNX model integration
5. Create comprehensive unit tests
6. Performance benchmarking 